\chapter{Conclusion}\label{chapter:conclusion}

In this thesis, I developed a novel method to extract the subcellular localization of proteins from the biomedical literature. I used common natural language processing (NLP) techniques and support vector machines (SVMs).

Given that existing datasets were not appropriate for the task of protein-location relation extraction, I and two other annotators annotated a new corpus, "LocText". LocText consists of 100 MEDLINE \cite{medline} abstracts, containing mentions of the subcellular localization of diverse proteins. In addition to the abstracts, LocText also contains 4 PMC \cite{pmc} full-text articles. The annotation of documents was done with the help of the \textit{tagtog} web interface \cite{cejuela2014tagtog}. The documents in LocText were annotated for protein entities, location entities, organism entities, protein-organism relations, and protein-location relations.

We found out that around 60\% of the protein-location relations in the abstract subcorpus are same-sentence relations, i.e., both the protein and location entities are present in the same sentence. Interestingly high, for around 81\% of the protein-location relations in the abstract subcorpus, the participating entities are either present in the same sentence or in neighboring sentences (1 sentence apart).
% j: This doesn't really add anything: > The remaining 40\% of the protein-location relations in the abstract subcorpus are different-sentence relations, i.e., the participating entities are present in different sentences.

I developed two models (both SVMs), one for extracting same-sentence relations, \textit{SSModel}, and other one for extracting different-sentence relations, \textit{DSModel}. Despite the name, the \textit{DSModel} was used for extracting relations in which the participating entities are only 1 sentence apart. The feature set of \textit{SSModel} differs only slightly compared to the feature set of the \textit{DSModel}. Features were derived from three sources: text, syntactic parse tree and dependency parse tree. In both models, a sentence is represented as a graph, with the tokens in the sentence forming the nodes of the graph and the dependency relations between the tokens, acting as edges of the graph. Many graph-based features played an important role in prediction performance. Furthermore, I experimented extensively with feature selection. Using \emph{information gain}, I could markedly reduce the number of features while increasing the overall performance of both models: for \textit{SSModel} from 154421 features to 66188 and for \textit{DSModel} from 310512 features to 92514. In some occasions, for example deciding not to use \emph{coreference resolution} in features, speed was preferred over performance. Further possible improvements on the method are explained in Section \ref{chapter:outlook}.

I used 5-fold cross validation on the abstract subcorpus for evaluation. The combined predictions of \textit{SSModel} and \textit{DSModel} achieved a precision of 66.57\%, recall of 67.61\% and F-score of 66.73\% on the development set and a precision of 61.01\%, recall of 66.55\% and F-score of 63.15\% on the test set.

For the full-text subcorpus, it was found out that 92.2\% of the protein-location relations are same-sentence relations. I used \textit{SSModel} for a preliminary evaluation on the full-text subcorpus. Using 4-fold cross validation, the method achieved a precision of 61.9\%, recall of 86.66\% and F-score of 68.2\% on the test set.

\textbf{TODO}: last paragraph telling the relevance of your work: 1) released novel corpus, already published in a paper and put in 2 external archives, tagtog and PubAnnotation, 2) novel method specifically built for protein-location relation extraction, 3) first evaluation results on full-text articles.